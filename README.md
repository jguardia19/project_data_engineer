# Proyecto Final - Ingeniero de Datos de IA

**Curso:** Procesos ETL para Cargas de Trabajo de IA
**Programa:** CertificaciÃ³n de Ingeniero de Datos de IA
**Estudiante:** JosÃ© Gregorio Guardia
**TecnologÃ­as:** YOLO v11, Apache Hive, Apache Hadoop, Python ETL

---

## ğŸ“‹ DescripciÃ³n General

Este proyecto integra **Deep Learning**, **VisiÃ³n por Computador** y **Procesamiento Big Data** en una soluciÃ³n end-to-end compuesta por **dos sistemas claramente separados**:

1. **Sistema de ClasificaciÃ³n**: Ejecuta YOLO sobre imÃ¡genes y videos, extrae atributos enriquecidos y escribe detecciones en archivos CSV locales (capa de staging).

2. **Sistema Batch/ETL**: Lee los CSV generados, realiza limpieza, transformaciÃ³n y carga los datos procesados a Apache Hive en lotes, garantizando que no exista informaciÃ³n duplicada.

---

## ğŸ—ï¸ Arquitectura de Dos Sistemas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SISTEMA DE CLASIFICACIÃ“N                      â”‚
â”‚  ğŸ“¸ ImÃ¡genes/Videos â†’ ğŸ¤– YOLO v11 â†’ ğŸ“Š ExtracciÃ³n Atributos     â”‚
â”‚                           â†“                                      â”‚
â”‚                    ğŸ“ CSV Locales (Staging)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     SISTEMA BATCH/ETL                            â”‚
â”‚  ğŸ“ CSV â†’ ğŸ§¹ Limpieza â†’ ğŸ”„ TransformaciÃ³n â†’ ğŸ—„ï¸ Apache Hive     â”‚
â”‚  (Lotes de 10s para videos, batch completo para imÃ¡genes)       â”‚
â”‚  âœ… Sin duplicados garantizado                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                      ğŸ“ˆ Consultas AnalÃ­ticas
```

---

## ğŸš€ CaracterÃ­sticas Principales

### Sistema de ClasificaciÃ³n
- âœ… DetecciÃ³n de objetos con **YOLO v11** (15+ objetos en imÃ¡genes, 10+ en videos)
- âœ… ExtracciÃ³n de **26+ atributos** por objeto detectado
- âœ… CÃ¡lculo de **color dominante** con OpenCV
- âœ… AnÃ¡lisis de **posiciÃ³n espacial** y regiÃ³n del frame
- âœ… GeneraciÃ³n de **CSV locales** como capa de staging
- âœ… **NO se conecta a Hive** (separaciÃ³n de responsabilidades)

### Sistema Batch/ETL
- âœ… Procesamiento **solo con Python** (sin PySpark)
- âœ… **Limpieza y transformaciÃ³n** de datos
- âœ… EnvÃ­o en **lotes de 10 segundos** para videos
- âœ… EnvÃ­o **completo al finalizar** para imÃ¡genes
- âœ… **GarantÃ­a de no duplicados** en Hive
- âœ… Estrategia de **checkpoint** para sincronizaciÃ³n

### Calidad de CÃ³digo
- âœ… **Makefile** para automatizaciÃ³n completa
- âœ… **Pruebas unitarias** con pytest
- âœ… **Linting** con pylint
- âœ… **DocumentaciÃ³n** completa con docstrings
- âœ… **Logging** detallado del proceso

---

## ğŸ“ Estructura del Proyecto

```
project_data_engineer/
â”œâ”€â”€ ğŸ“¸ imagenes_entrada/              # 20+ imÃ¡genes capturadas
â”œâ”€â”€ ğŸ¬ videos_entrada/                # 2+ videos (max 20s o 50MB)
â”œâ”€â”€ ğŸ“Š imagenes_procesadas/           # CSVs generados (staging)
â”œâ”€â”€ ğŸ src/                           # CÃ³digo fuente
â”‚   â”œâ”€â”€ sistema_clasificacion.py      # Sistema 1: YOLO â†’ CSV
â”‚   â”œâ”€â”€ sistema_batch_etl.py          # Sistema 2: CSV â†’ Hive
â”‚   â””â”€â”€ test_clasificacion.py         # Pruebas del sistema 1
â”‚   â””â”€â”€ test_etl.py                   # Pruebas del sistema 2
â”œâ”€â”€ ğŸ§ª tests/                         # Pruebas unitarias adicionales
â”‚   â”œâ”€â”€ test_clasificacion.py
â”‚   â”œâ”€â”€ test_sistema.py
â”‚   â””â”€â”€ test_hive_local_wsl.py
â”œâ”€â”€ ğŸ“‹ sql/                           # Consultas analÃ­ticas (5+)
â”‚   â”œâ”€â”€ 01_consultas_basicas.sql
â”‚   â”œâ”€â”€ 02_analisis_confianza.sql
â”‚   â”œâ”€â”€ 03_analisis_espacial.sql
â”‚   â”œâ”€â”€ 04_analisis_colores.sql
â”‚   â”œâ”€â”€ 05_analisis_temporal.sql
â”‚   â””â”€â”€ 06_reportes_avanzados.sql
â”œâ”€â”€ ğŸ”§ configuracion.py               # Configuraciones centralizadas
â”œâ”€â”€ ğŸš€ ejecutar_proyecto.py           # Script principal de ejecuciÃ³n
â”œâ”€â”€ ğŸ“„ Makefile                       # AutomatizaciÃ³n completa
â”œâ”€â”€ ğŸ“„ requerimientos.txt             # Dependencias Python
â”œâ”€â”€ ğŸ“– README.md                      # Esta documentaciÃ³n
â”œâ”€â”€ ğŸ“– GUIA_PROYECTO_FINAL_ES.md      # GuÃ­a del proyecto
â””â”€â”€ ğŸ³ enviroments/                   # Entorno virtual
```

---

## ğŸ› ï¸ Requisitos del Sistema

### 1. Sistema Operativo y Software Base
- **Ubuntu 24.04** (requerido)
- **Python 3.10** (instalado segÃºn guÃ­a oficial)
- **Apache HDFS** (instalado y funcionando)
- **Apache Hive** (instalado y funcionando)
- **GPU NVIDIA** (opcional, para aceleraciÃ³n CUDA)

### 2. InstalaciÃ³n de Python 3.10 y OpenCV
Seguir la guÃ­a oficial:
```
guias/Guia_Instalacion_Python310_OpenCV_v410.pdf
```

### 3. InstalaciÃ³n de OpenCV con CUDA (Opcional)
Si tienes GPU NVIDIA, seguir:
```
StepByStepToInstallOpenCVWithCudaSupport.txt
```

---

## âš™ï¸ ConfiguraciÃ³n del Entorno

### 1. Crear Entorno Virtual
```bash
# Crear entorno virtual
python3.10 -m venv enviroments/project_final

# Activar entorno (Linux/Ubuntu)
source enviroments/project_final/bin/activate

# Activar entorno (Windows WSL)
source enviroments/project_final/bin/activate
```

### 2. Instalar Dependencias con Makefile
```bash
# OpciÃ³n 1: Usar Makefile (recomendado)
make install

# OpciÃ³n 2: InstalaciÃ³n manual
pip install --upgrade pip
pip install -r requerimientos.txt
```

### 3. Verificar InstalaciÃ³n
```bash
# Verificar todas las dependencias
make test

# Verificar YOLO
python -c "from ultralytics import YOLO; print('âœ… YOLO OK')"

# Verificar Hive
python -c "from pyhive import hive; print('âœ… Hive OK')"

# Verificar OpenCV
python -c "import cv2; print('âœ… OpenCV OK')"
```

### 4. Configurar Apache Hive
```bash
# Verificar servicios Hadoop y Hive
jps | grep -E "(HiveServer2|RunJar|NameNode|DataNode)"

# Iniciar Hadoop (si no estÃ¡ corriendo)
start-dfs.sh
start-yarn.sh

# Iniciar Hive (si no estÃ¡ corriendo)
$HIVE_HOME/bin/hiveserver2 --hiveconf hive.server2.thrift.port=10000 &

# Verificar conexiÃ³n
beeline -u jdbc:hive2://localhost:10000
```

### 5. ConfiguraciÃ³n del Proyecto
Editar `configuracion.py` con tus parÃ¡metros:
```python
HIVE_CONFIG = {
    'host': 'localhost',
    'port': 10000,
    'username': 'tu_usuario',
    'database': 'yolo_project',
    'auth': 'NONE'
}
```

---

## ğŸš€ EjecuciÃ³n del Proyecto

### OpciÃ³n 1: EjecuciÃ³n Completa con Makefile (Recomendado)
```bash
# Ejecutar todo el pipeline (clasificaciÃ³n + ETL)
make run

# O ejecutar paso a paso
make run-clasificacion    # Solo Sistema de ClasificaciÃ³n
make run-etl             # Solo Sistema ETL
```

### OpciÃ³n 2: EjecuciÃ³n Manual de Sistemas Separados

#### Sistema 1: ClasificaciÃ³n (YOLO â†’ CSV)
```bash
# Activar entorno
source enviroments/project_final/bin/activate

# Ejecutar sistema de clasificaciÃ³n
python src/sistema_clasificacion.py

# Resultado: CSV generados en imagenes_procesadas/
```

#### Sistema 2: Batch/ETL (CSV â†’ Hive)
```bash
# Activar entorno
source enviroments/project_final/bin/activate

# Ejecutar sistema ETL
python src/sistema_batch_etl.py

# Resultado: Datos cargados en Hive sin duplicados
```

### OpciÃ³n 3: Script Principal Integrado
```bash
# Ejecutar pipeline completo
python ejecutar_proyecto.py
```

---

## ğŸ“Š Datos de Entrada

### ImÃ¡genes
- **Cantidad mÃ­nima:** 20 imÃ¡genes diferentes
- **UbicaciÃ³n:** `imagenes_entrada/`
- **Formato:** JPG, JPEG, PNG
- **Requisito:** Capturadas por el estudiante (no descargadas)
- **Contenido:** Deben contener objetos detectables (personas, vehÃ­culos, etc.)

### Videos
- **Cantidad mÃ­nima:** 2 videos
- **UbicaciÃ³n:** `videos_entrada/`
- **Formato:** MP4, MOV, AVI
- **DuraciÃ³n mÃ¡xima:** 20 segundos
- **TamaÃ±o mÃ¡ximo:** 50 MB por video
- **Requisito:** Capturados por el estudiante (no descargados)
- **Contenido:** Deben contener personas

---

## ğŸ¤– Sistema de ClasificaciÃ³n (Sistema 1)

### Responsabilidades
1. âœ… Cargar modelo YOLO v11
2. âœ… Procesar imÃ¡genes y videos
3. âœ… Detectar objetos (15+ en imÃ¡genes, 10+ en videos)
4. âœ… Extraer 26+ atributos por objeto
5. âœ… Escribir detecciones en CSV locales
6. âŒ **NO se conecta a Hive**

### Atributos ExtraÃ­dos (26+ por objeto)

#### A. InformaciÃ³n BÃ¡sica
- `source_type` - "image" o "video"
- `source_id` - nombre del archivo
- `frame_number` - 0 para imÃ¡genes, nÃºmero de frame en video
- `class_id` - ID numÃ©rico de la clase
- `class_name` - nombre de la clase detectada
- `confidence` - confianza de la detecciÃ³n (0-1)

#### B. Bounding Box
- `x_min`, `y_min`, `x_max`, `y_max` - coordenadas del bbox
- `width`, `height` - dimensiones del bbox
- `area_pixels` - Ã¡rea del bbox en pÃ­xeles
- `frame_width`, `frame_height` - dimensiones del frame
- `bbox_area_ratio` - proporciÃ³n del bbox respecto al frame

#### C. PosiciÃ³n Espacial
- `center_x`, `center_y` - centro del bbox
- `center_x_norm`, `center_y_norm` - centro normalizado (0-1)
- `position_region` - regiÃ³n del frame (top-left, middle-center, etc.)

#### D. Color Dominante (OpenCV)
- `dominant_color_name` - nombre del color (red, green, blue, etc.)
- `dom_r`, `dom_g`, `dom_b` - componentes RGB del color dominante

#### E. Metadatos Temporales
- `timestamp_sec` - tiempo del frame en segundos (videos)
- `ingestion_date` - fecha/hora de procesamiento
- `detection_id` - identificador Ãºnico de la detecciÃ³n

### Ejemplo de EjecuciÃ³n
```bash
python src/sistema_clasificacion.py

# Salida esperada:
# âœ… Procesando imÃ¡genes...
# âœ… Procesando videos...
# âœ… CSV generados en: imagenes_procesadas/
# âœ… Total detecciones: 1234
```

---

## ï¿½ Sistema Batch/ETL (Sistema 2)

### Responsabilidades
1. âœ… Leer CSV generados por Sistema 1
2. âœ… Limpieza de datos (nulos, valores invÃ¡lidos)
3. âœ… TransformaciÃ³n y normalizaciÃ³n
4. âœ… Carga a Hive en lotes
5. âœ… **Garantizar NO duplicados**

### Reglas de EnvÃ­o de Lotes

#### Para ImÃ¡genes
- Se envÃ­an **al finalizar** el procesamiento de todas las imÃ¡genes
- Un solo lote con todas las detecciones de imÃ¡genes

#### Para Videos
- Se envÃ­an en **ventanas de 10 segundos** de contenido
- Ejemplo para video de 40 segundos:
  - Lote 1: frames 0-10s
  - Lote 2: frames 10-20s
  - Lote 3: frames 20-30s
  - Lote 4: frames 30-40s

### Estrategia Anti-Duplicados

El sistema implementa **mÃºltiples mecanismos** para evitar duplicados:

1. **Clave Ãºnica compuesta:**
   ```python
   detection_id = f"{source_id}_{frame_number}_{class_id}_{bbox_hash}"
   ```

2. **Checkpoint de procesamiento:**
   - Archivo `imagenes_procesadas/checkpoint.json`
   - Registra quÃ© archivos ya fueron procesados
   - Evita re-procesar datos ya cargados

3. **ValidaciÃ³n pre-inserciÃ³n:**
   - Consulta a Hive antes de insertar
   - Filtra registros ya existentes

### Proceso ETL Completo

```python
# 1. EXTRACCIÃ“N
csv_files = leer_csv_staging()

# 2. LIMPIEZA
datos_limpios = limpiar_datos(csv_files)
# - Eliminar nulos
# - Validar rangos (confidence 0-1)
# - Validar coordenadas

# 3. TRANSFORMACIÃ“N
datos_transformados = transformar_datos(datos_limpios)
# - Normalizar tipos
# - Calcular campos derivados
# - Agrupar por lotes (10s para videos)

# 4. CARGA
cargar_a_hive(datos_transformados)
# - Verificar duplicados
# - Insertar en Hive
# - Actualizar checkpoint
```

### Ejemplo de EjecuciÃ³n
```bash
python src/sistema_batch_etl.py

# Salida esperada:
# âœ… Conectando a Hive...
# âœ… Leyendo CSV de staging...
# âœ… Limpiando datos...
# âœ… Transformando datos...
# âœ… Cargando lote 1/4 (video: 0-10s)...
# âœ… Cargando lote 2/4 (video: 10-20s)...
# âœ… Cargando lote imÃ¡genes...
# âœ… Total registros cargados: 1234
# âœ… Duplicados evitados: 0
```

---

## ğŸ—„ï¸ Esquema de Hive

### Tabla Principal: yolo_objects

```sql
CREATE EXTERNAL TABLE IF NOT EXISTS yolo_objects (
    -- InformaciÃ³n BÃ¡sica
    source_type           STRING,
    source_id             STRING,
    frame_number          INT,
    class_id              INT,
    class_name            STRING,
    confidence            DOUBLE,

    -- Bounding Box
    x_min                 INT,
    y_min                 INT,
    x_max                 INT,
    y_max                 INT,
    width                 INT,
    height                INT,
    area_pixels           INT,
    frame_width           INT,
    frame_height          INT,
    bbox_area_ratio       DOUBLE,

    -- PosiciÃ³n Espacial
    center_x              DOUBLE,
    center_y              DOUBLE,
    center_x_norm         DOUBLE,
    center_y_norm         DOUBLE,
    position_region       STRING,

    -- Color Dominante
    dominant_color_name   STRING,
    dom_r                 INT,
    dom_g                 INT,
    dom_b                 INT,

    -- Metadatos
    timestamp_sec         DOUBLE,
    ingestion_date        STRING,
    detection_id          STRING
)
STORED AS PARQUET
LOCATION 'hdfs:///projects/yolo_objects/hive/';
```

### CreaciÃ³n de Base de Datos
```sql
-- Crear base de datos
CREATE DATABASE IF NOT EXISTS yolo_project;
USE yolo_project;

-- Verificar tabla
SHOW TABLES;
DESCRIBE FORMATTED yolo_objects;
```

---

## ğŸ“ˆ Consultas AnalÃ­ticas en Hive

El proyecto incluye **5+ consultas analÃ­ticas** en la carpeta `sql/`:

### 1. Consultas BÃ¡sicas (`01_consultas_basicas.sql`)
```sql
-- Conteo de objetos por clase
SELECT class_name, COUNT(*) as total_detecciones
FROM yolo_objects
GROUP BY class_name
ORDER BY total_detecciones DESC;

-- NÃºmero de personas por video
SELECT source_id, COUNT(*) as total_personas
FROM yolo_objects
WHERE class_name = 'person' AND source_type = 'video'
GROUP BY source_id;
```

### 2. AnÃ¡lisis de Confianza (`02_analisis_confianza.sql`)
```sql
-- Confianza promedio por clase
SELECT class_name,
       AVG(confidence) as avg_confidence,
       MIN(confidence) as min_confidence,
       MAX(confidence) as max_confidence
FROM yolo_objects
GROUP BY class_name;
```

### 3. AnÃ¡lisis Espacial (`03_analisis_espacial.sql`)
```sql
-- Ãrea promedio de bounding boxes por clase
SELECT class_name,
       AVG(area_pixels) as avg_area,
       AVG(bbox_area_ratio) as avg_ratio
FROM yolo_objects
GROUP BY class_name;

-- DistribuciÃ³n por regiÃ³n del frame
SELECT position_region, COUNT(*) as total
FROM yolo_objects
GROUP BY position_region;
```

### 4. AnÃ¡lisis de Colores (`04_analisis_colores.sql`)
```sql
-- DistribuciÃ³n de colores dominantes por clase
SELECT class_name, dominant_color_name, COUNT(*) as total
FROM yolo_objects
GROUP BY class_name, dominant_color_name
ORDER BY class_name, total DESC;
```

### 5. AnÃ¡lisis Temporal (`05_analisis_temporal.sql`)
```sql
-- NÃºmero de objetos por ventana de 10 segundos en cada video
SELECT source_id,
       FLOOR(timestamp_sec / 10) * 10 as ventana_inicio,
       COUNT(*) as objetos_detectados
FROM yolo_objects
WHERE source_type = 'video'
GROUP BY source_id, FLOOR(timestamp_sec / 10)
ORDER BY source_id, ventana_inicio;
```

### Ejecutar Consultas
```bash
# OpciÃ³n 1: Desde Hive CLI
beeline -u jdbc:hive2://localhost:10000 -f sql/01_consultas_basicas.sql

# OpciÃ³n 2: Con script Python
python sql/ejecutar_queries.py

# OpciÃ³n 3: Con Makefile
make queries
```

---

## ğŸ§ª Pruebas y Calidad de CÃ³digo

### Estructura de Pruebas
```
tests/
â”œâ”€â”€ test_clasificacion.py      # Pruebas del Sistema 1
â”œâ”€â”€ test_sistema.py            # Pruebas integradas
â””â”€â”€ test_hive_local_wsl.py     # Pruebas de conexiÃ³n Hive
```

### Ejecutar Pruebas
```bash
# OpciÃ³n 1: Con Makefile (recomendado)
make test

# OpciÃ³n 2: Con pytest directamente
pytest tests/ -v

# OpciÃ³n 3: Pruebas especÃ­ficas
pytest tests/test_clasificacion.py -v
pytest tests/test_sistema.py -v
```

### Linting y Formateo
```bash
# Ejecutar pylint
make lint

# Formatear cÃ³digo
make format

# Verificar todo (lint + test)
make check
```

### Cobertura de Pruebas
```bash
# Generar reporte de cobertura
make coverage

# Ver reporte HTML
make coverage-html
```

---

## ğŸ“‹ Uso del Makefile

El proyecto incluye un **Makefile completo** para automatizaciÃ³n:

```bash
# Ver todos los comandos disponibles
make help

# Comandos principales:
make install          # Instalar dependencias
make test            # Ejecutar pruebas
make lint            # Ejecutar pylint
make format          # Formatear cÃ³digo
make run             # Ejecutar pipeline completo
make run-clasificacion  # Solo clasificaciÃ³n
make run-etl         # Solo ETL
make queries         # Ejecutar consultas SQL
make clean           # Limpiar archivos temporales
make check           # Lint + Test
```

---

## ğŸ“Š Monitoreo y Logs

### Archivos de Log
El sistema genera logs detallados:
- `logs/clasificacion.log` - Logs del Sistema de ClasificaciÃ³n
- `logs/etl.log` - Logs del Sistema ETL
- `logs/pipeline.log` - Logs del pipeline completo

### Niveles de Log
```python
# ConfiguraciÃ³n en configuracion.py
LOGGING_CONFIG = {
    'level': 'INFO',  # DEBUG, INFO, WARNING, ERROR
    'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
}
```

### Ver Logs en Tiempo Real
```bash
# Seguir logs de clasificaciÃ³n
tail -f logs/clasificacion.log

# Seguir logs de ETL
tail -f logs/etl.log
```

---

## ğŸ”§ SoluciÃ³n de Problemas

### Error: No se puede conectar a Hive
```bash
# 1. Verificar que Hive estÃ© corriendo
jps | grep HiveServer2

# 2. Verificar que Hadoop estÃ© corriendo
jps | grep -E "(NameNode|DataNode)"

# 3. Iniciar servicios si es necesario
start-dfs.sh
start-yarn.sh
$HIVE_HOME/bin/hiveserver2 --hiveconf hive.server2.thrift.port=10000 &

# 4. Probar conexiÃ³n
beeline -u jdbc:hive2://localhost:10000
```

### Error: MÃ³dulo 'pyhive' no encontrado
```bash
# Reinstalar dependencias
pip install --upgrade pip
pip install -r requerimientos.txt

# Verificar instalaciÃ³n
python -c "from pyhive import hive; print('âœ… Hive OK')"
```

### Error: YOLO no detecta objetos
```bash
# Verificar instalaciÃ³n de YOLO
python -c "from ultralytics import YOLO; print('âœ… YOLO OK')"

# Verificar modelo descargado
ls -lh yolo11n.pt

# Re-descargar modelo si es necesario
python -c "from ultralytics import YOLO; YOLO('yolo11n.pt')"
```

### Error: OpenCV no encuentra CUDA
```bash
# Verificar instalaciÃ³n de OpenCV
python -c "import cv2; print(cv2.getBuildInformation())"

# Si no tiene CUDA, reinstalar siguiendo:
# StepByStepToInstallOpenCVWithCudaSupport.txt
```

### Error: Duplicados en Hive
```bash
# Limpiar tabla y checkpoint
beeline -u jdbc:hive2://localhost:10000 -e "TRUNCATE TABLE yolo_project.yolo_objects;"
rm imagenes_procesadas/checkpoint.json

# Re-ejecutar ETL
python src/sistema_batch_etl.py
```

---

## ğŸ“ˆ Resultados Esperados

### Al ejecutar el Sistema de ClasificaciÃ³n:
1. âœ… Procesamiento de 20+ imÃ¡genes
2. âœ… Procesamiento de 2+ videos
3. âœ… DetecciÃ³n de 15+ objetos en imÃ¡genes
4. âœ… DetecciÃ³n de 10+ objetos en videos
5. âœ… GeneraciÃ³n de CSV con 26+ atributos por objeto
6. âœ… CSV guardados en `imagenes_procesadas/`

### Al ejecutar el Sistema ETL:
1. âœ… Lectura de CSV de staging
2. âœ… Limpieza de datos (nulos, valores invÃ¡lidos)
3. âœ… TransformaciÃ³n y normalizaciÃ³n
4. âœ… Carga en lotes de 10s para videos
5. âœ… Carga completa para imÃ¡genes
6. âœ… **0 duplicados** en Hive
7. âœ… Checkpoint actualizado

### Al ejecutar Consultas AnalÃ­ticas:
1. âœ… EstadÃ­sticas por clase de objeto
2. âœ… AnÃ¡lisis de confianza
3. âœ… DistribuciÃ³n espacial
4. âœ… AnÃ¡lisis de colores
5. âœ… AnÃ¡lisis temporal (ventanas de 10s)

---



## ğŸ“š DocumentaciÃ³n Adicional

### GuÃ­as Incluidas
- `guias/Guia_Instalacion_Python310_OpenCV_v410.pdf` - InstalaciÃ³n de Python 3.10
- `guias/Manual_Instalacion_Apache_Hive.pdf` - InstalaciÃ³n de Hive
- `guias/Manual_Instalacion_Hadoop_3.4.2_BSG_Institute.pdf` - InstalaciÃ³n de Hadoop
- `StepByStepToInstallOpenCVWithCudaSupport.txt` - OpenCV con CUDA

### Referencias Externas
- [DocumentaciÃ³n YOLO v11](https://docs.ultralytics.com/)
- [Apache Hive Documentation](https://hive.apache.org/)
- [Apache Hadoop Documentation](https://hadoop.apache.org/)
- [OpenCV Documentation](https://docs.opencv.org/)

---

## ğŸ¯ Casos de Uso del Proyecto

- **ğŸ”’ Seguridad y Vigilancia:** DetecciÃ³n de personas y objetos en tiempo real
- **ğŸš— AnÃ¡lisis de TrÃ¡fico:** Conteo de vehÃ­culos y peatones
- **ğŸª Retail Analytics:** AnÃ¡lisis de comportamiento de clientes
- **ğŸ­ Seguridad Industrial:** DetecciÃ³n de incidentes y anomalÃ­as
- **ğŸ“Š Big Data Analytics:** Procesamiento masivo de datos visuales

---

## ğŸ‘¨â€ğŸ’» Autor

**JosÃ© Gregorio Guardia**
Programa de CertificaciÃ³n de Ingeniero de Datos de IA
Curso: Procesos ETL para Cargas de Trabajo de IA

---

## ğŸš€ Inicio RÃ¡pido

```bash
# 1. Activar entorno virtual
source enviroments/project_final/bin/activate

# 2. Instalar dependencias
make install

# 3. Verificar instalaciÃ³n
make test

# 4. Ejecutar pipeline completo
make run

# 5. Ejecutar consultas analÃ­ticas
make queries
```

---

## ğŸ“ Notas Finales

Este proyecto cumple con todos los requisitos del **Proyecto Final** del curso:

âœ… **Arquitectura de dos sistemas separados** (ClasificaciÃ³n + ETL)
âœ… **Python 3.10** en Ubuntu 24.04
âœ… **YOLO v11** para detecciÃ³n de objetos
âœ… **26+ atributos** extraÃ­dos por objeto
âœ… **CSV como capa de staging**
âœ… **ETL solo con Python** (sin PySpark)
âœ… **Lotes de 10 segundos** para videos
âœ… **Sin duplicados** en Hive
âœ… **Makefile** completo
âœ… **Pruebas unitarias** con pytest
âœ… **5+ consultas analÃ­ticas** en Hive
âœ… **DocumentaciÃ³n completa**

**Â¡El sistema estÃ¡ listo para producciÃ³n!** ğŸ‰
